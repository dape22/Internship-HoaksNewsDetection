{"cells":[{"cell_type":"markdown","metadata":{"id":"FfyykYDewUN2"},"source":["## Upload Data"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3699,"status":"ok","timestamp":1700976009926,"user":{"displayName":"Dhani Aditya","userId":"04682861847732937940"},"user_tz":-420},"id":"-wXU9lhecKdX"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv('G:\\\\My Drive\\\\Tugas SEM3\\\\Kecerdasan Artifisial\\\\Project AI\\\\datajadi.csv')\n","# df1 = pd.read_csv('G:\\\\My Drive\\\\Tugas SEM3\\\\Pemrosesan Teks\\\\Project Pemro\\\\data_resample1.csv')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":521},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1700971078240,"user":{"displayName":"Dhani Aditya","userId":"04682861847732937940"},"user_tz":-420},"id":"eD4gK_FqQFq6","outputId":"58b19550-24ef-4554-90c1-5d82c5c19905"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>judulpluskonten</th>\n","      <th>preproses_text</th>\n","      <th>Number of Determinants</th>\n","      <th>Number of Short Sentence</th>\n","      <th>Number of Long Sentence</th>\n","      <th>smog_index</th>\n","      <th>Subjectivity</th>\n","      <th>Number of Syllables</th>\n","      <th>Rate Adjective and Adverb</th>\n","      <th>Number of Sentences</th>\n","      <th>...</th>\n","      <th>number of special karakter</th>\n","      <th>number of capital letter</th>\n","      <th>gunning_fog_index</th>\n","      <th>ari</th>\n","      <th>number of word</th>\n","      <th>word per sentence</th>\n","      <th>number of verb</th>\n","      <th>number of adjective</th>\n","      <th>label</th>\n","      <th>vec</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Health insurers quietly shape Obamacare replac...</td>\n","      <td>health insur quietli shape obamacar replac few...</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>38</td>\n","      <td>15.0</td>\n","      <td>0.395471</td>\n","      <td>1614</td>\n","      <td>58.0</td>\n","      <td>148</td>\n","      <td>...</td>\n","      <td>124</td>\n","      <td>150</td>\n","      <td>13.43</td>\n","      <td>19.987545</td>\n","      <td>1006</td>\n","      <td>30.216216</td>\n","      <td>136</td>\n","      <td>83</td>\n","      <td>0</td>\n","      <td>[ 0.02840978  0.00446486 -0.00950904  0.032875...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Migrants Refuse To Leave Train At Refugee Camp...</td>\n","      <td>migrant refus leav train refuge camp hungarymi...</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>18</td>\n","      <td>11.1</td>\n","      <td>0.289697</td>\n","      <td>753</td>\n","      <td>28.0</td>\n","      <td>82</td>\n","      <td>...</td>\n","      <td>85</td>\n","      <td>115</td>\n","      <td>10.67</td>\n","      <td>15.822994</td>\n","      <td>486</td>\n","      <td>25.545455</td>\n","      <td>67</td>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>[ 0.02864144  0.004986   -0.01179579  0.033683...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Manafort meets with Senate intelligence panel:...</td>\n","      <td>manafo meet senat intellig panel spokesmanwash...</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>15.9</td>\n","      <td>0.222222</td>\n","      <td>166</td>\n","      <td>2.5</td>\n","      <td>12</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>37</td>\n","      <td>15.92</td>\n","      <td>23.579263</td>\n","      <td>95</td>\n","      <td>37.666667</td>\n","      <td>13</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>[ 3.06978021e-02  4.67474674e-05 -1.02226874e-...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CBO Releases Score of Paul Ryan’s American Hea...</td>\n","      <td>cbo releas score paul ryan american health car...</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0.0</td>\n","      <td>0.210000</td>\n","      <td>84</td>\n","      <td>2.5</td>\n","      <td>8</td>\n","      <td>...</td>\n","      <td>17</td>\n","      <td>55</td>\n","      <td>16.27</td>\n","      <td>21.590125</td>\n","      <td>63</td>\n","      <td>40.000000</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>[ 0.03636537 -0.00171204 -0.01732128  0.036230...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Conservatives Urge Sessions to Clean Out Obama...</td>\n","      <td>conserv urg session clean obama civil right di...</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>13</td>\n","      <td>18.0</td>\n","      <td>0.366094</td>\n","      <td>743</td>\n","      <td>18.5</td>\n","      <td>52</td>\n","      <td>...</td>\n","      <td>64</td>\n","      <td>97</td>\n","      <td>18.41</td>\n","      <td>23.542137</td>\n","      <td>409</td>\n","      <td>36.846154</td>\n","      <td>45</td>\n","      <td>28</td>\n","      <td>0</td>\n","      <td>[ 0.02952077  0.00713297 -0.01201566  0.031389...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["                                     judulpluskonten  \\\n","0  Health insurers quietly shape Obamacare replac...   \n","1  Migrants Refuse To Leave Train At Refugee Camp...   \n","2  Manafort meets with Senate intelligence panel:...   \n","3  CBO Releases Score of Paul Ryan’s American Hea...   \n","4  Conservatives Urge Sessions to Clean Out Obama...   \n","\n","                                      preproses_text  Number of Determinants  \\\n","0  health insur quietli shape obamacar replac few...                       4   \n","1  migrant refus leav train refuge camp hungarymi...                       4   \n","2  manafo meet senat intellig panel spokesmanwash...                       4   \n","3  cbo releas score paul ryan american health car...                       4   \n","4  conserv urg session clean obama civil right di...                       4   \n","\n","   Number of Short Sentence  Number of Long Sentence  smog_index  \\\n","0                         3                       38        15.0   \n","1                         2                       18        11.1   \n","2                         1                        3        15.9   \n","3                         0                        2         0.0   \n","4                         1                       13        18.0   \n","\n","   Subjectivity  Number of Syllables  Rate Adjective and Adverb  \\\n","0      0.395471                 1614                       58.0   \n","1      0.289697                  753                       28.0   \n","2      0.222222                  166                        2.5   \n","3      0.210000                   84                        2.5   \n","4      0.366094                  743                       18.5   \n","\n","   Number of Sentences  ...  number of special karakter  \\\n","0                  148  ...                         124   \n","1                   82  ...                          85   \n","2                   12  ...                          18   \n","3                    8  ...                          17   \n","4                   52  ...                          64   \n","\n","   number of capital letter  gunning_fog_index        ari  number of word  \\\n","0                       150              13.43  19.987545            1006   \n","1                       115              10.67  15.822994             486   \n","2                        37              15.92  23.579263              95   \n","3                        55              16.27  21.590125              63   \n","4                        97              18.41  23.542137             409   \n","\n","   word per sentence  number of verb  number of adjective  label  \\\n","0          30.216216             136                   83      0   \n","1          25.545455              67                   34      0   \n","2          37.666667              13                    3      0   \n","3          40.000000               5                    3      0   \n","4          36.846154              45                   28      0   \n","\n","                                                 vec  \n","0  [ 0.02840978  0.00446486 -0.00950904  0.032875...  \n","1  [ 0.02864144  0.004986   -0.01179579  0.033683...  \n","2  [ 3.06978021e-02  4.67474674e-05 -1.02226874e-...  \n","3  [ 0.03636537 -0.00171204 -0.01732128  0.036230...  \n","4  [ 0.02952077  0.00713297 -0.01201566  0.031389...  \n","\n","[5 rows x 21 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(df.head())"]},{"cell_type":"markdown","metadata":{"id":"4BnNGGuIEMlV"},"source":["## import library yang dibutuhkan"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":372,"status":"ok","timestamp":1700976399883,"user":{"displayName":"Dhani Aditya","userId":"04682861847732937940"},"user_tz":-420},"id":"glUeWMZuDvnQ"},"outputs":[],"source":["import numpy as np\n","from random import randint\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from sklearn import svm\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import  AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold, cross_val_score\n","from sklearn.feature_extraction.text import CountVectorizer\n","from scipy.sparse import hstack\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["classifiers = ['LinearSVM', 'RadialSVM', \n","               'Logistic',  'RandomForest', \n","               'AdaBoost',  'DecisionTree', \n","               'KNeighbors','GradientBoosting']\n","\n","models = [svm.SVC(kernel='linear'),\n","          svm.SVC(kernel='rbf'),\n","          LogisticRegression(max_iter = 1000),\n","          RandomForestClassifier(n_estimators=200, random_state=0),\n","          AdaBoostClassifier(random_state = 0),\n","          DecisionTreeClassifier(random_state=0),\n","          KNeighborsClassifier(),\n","          GradientBoostingClassifier(random_state=0)]\n","\n","\n","def acc_score(X_train,X_test,y_train,y_test):\n","    Score = pd.DataFrame({\"Classifier\":classifiers})\n","    j = 0\n","    acc = []\n","    for i in models:\n","        model = i\n","        model.fit(X_train,y_train)\n","        predictions = model.predict(X_test)\n","        acc.append(accuracy_score(y_test,predictions))\n","        j = j+1     \n","    Score[\"Accuracy\"] = acc\n","    Score.sort_values(by=\"Accuracy\", ascending=False,inplace = True)\n","    Score.reset_index(drop=True, inplace=True)\n","    return Score\n","    "]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Generation 1, Best Fitness: 0.8578\n","Generation 2, Best Fitness: 0.8508\n","Generation 3, Best Fitness: 0.8528\n","Generation 4, Best Fitness: 0.8558\n","Generation 5, Best Fitness: 0.8558\n","Generation 1: Selected features for each individual: [array([ 1,  5,  6,  7, 10, 14, 16], dtype=int64), array([ 2,  4,  6,  8,  9, 11, 13, 14, 15, 16], dtype=int64), array([ 0,  1,  2,  3,  4,  6,  8,  9, 11, 13, 14, 15, 16], dtype=int64), array([ 1,  5,  6,  9, 10, 11, 12], dtype=int64), array([ 0,  1,  2,  3,  4,  5,  6,  8, 14, 15, 16], dtype=int64), array([ 1,  3,  5,  6,  9, 10, 11, 12], dtype=int64), array([ 1,  3,  4,  7,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 0,  2,  3,  4,  5,  6,  8, 10, 12, 13, 14], dtype=int64), array([ 1,  3,  4,  7,  8,  9, 12, 14, 16], dtype=int64), array([ 2,  3,  4,  5,  6,  8, 14, 15, 16], dtype=int64)]\n","Generation 2: Selected features for each individual: [array([ 1,  5,  6,  9, 10, 11, 12], dtype=int64), array([ 1,  3,  4,  7,  8,  9, 12, 14, 16], dtype=int64), array([ 1,  5,  6,  9, 10, 11, 12], dtype=int64), array([ 1,  3,  4,  7,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 4,  5,  6,  8,  9, 11, 13], dtype=int64), array([ 0,  1,  3,  5,  6,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 1,  3,  4,  7,  9, 10, 11, 12, 14, 16], dtype=int64), array([ 1,  3,  4,  7,  8,  9, 12, 14, 15, 16], dtype=int64), array([ 1,  6,  7, 10, 14, 15, 16], dtype=int64), array([ 0,  1,  2,  3,  4,  6,  8,  9, 11, 13, 14, 16], dtype=int64)]\n","Generation 3: Selected features for each individual: [array([ 0,  1,  2,  3,  5,  7,  9, 10, 11, 12, 14, 16], dtype=int64), array([ 1,  3,  4,  6,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 0,  1,  2,  3,  4,  6,  8,  9, 11, 12, 14, 15, 16], dtype=int64), array([ 0,  1,  3,  5,  6,  9, 10, 11, 13, 14, 16], dtype=int64), array([ 1,  6,  7, 10, 14, 15, 16], dtype=int64), array([ 1,  3,  4,  7,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 0,  1,  2,  3,  4,  6,  8, 10, 14, 15, 16], dtype=int64), array([ 1,  6,  7,  9, 11, 13, 14, 16], dtype=int64), array([ 1,  3,  5,  6,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 0,  1,  5,  6,  9, 10, 11, 12], dtype=int64)]\n","Generation 4: Selected features for each individual: [array([ 0,  1,  2,  3,  5,  7,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 1,  3,  4,  7,  9, 10, 11, 12, 14, 16], dtype=int64), array([ 1,  3,  4,  6,  8, 10, 14, 15, 16], dtype=int64), array([ 0,  1,  2,  3,  4,  7,  9, 10, 12, 14, 15, 16], dtype=int64), array([ 1,  3,  5,  6,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 1,  3,  4,  6,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 0,  1,  3,  4,  6,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 1,  3,  5,  6,  9, 10, 11, 13, 14, 16], dtype=int64), array([ 0,  1,  2,  3,  4,  7,  9, 10, 11, 12, 14, 16], dtype=int64), array([ 0,  1,  2,  3,  5,  6,  8,  9, 11, 12, 14, 15, 16], dtype=int64)]\n","Generation 5: Selected features for each individual: [array([ 1,  3,  6,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 1,  2,  3,  4,  5,  6,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 0,  1,  2,  3,  5,  6,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 1,  3,  5,  7,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 0,  1,  2,  3,  4,  7,  9, 10, 11, 12, 14, 16], dtype=int64), array([ 0,  1,  2,  3,  5,  7,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 1,  3,  4,  7,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 1,  3,  4,  6,  9, 10, 11, 12, 14, 16], dtype=int64), array([ 0,  3,  4,  6,  9, 10, 11, 12, 14, 15, 16], dtype=int64), array([ 1,  3,  4,  6,  9, 10, 11, 12, 14, 15, 16], dtype=int64)]\n"]}],"source":["def initialize_population(num_individuals, num_features):\n","    return np.random.choice([0, 1], size=(num_individuals, num_features))\n","\n","def fitness(individual, X_train, X_test, y_train, y_test):\n","    selected_features = X_train.columns[individual == 1]\n","    clf = RandomForestClassifier(n_estimators=200, random_state=0)\n","    clf.fit(X_train[selected_features], y_train)\n","    y_pred = clf.predict(X_test[selected_features])\n","    return accuracy_score(y_test, y_pred)\n","\n","def crossover(parent1, parent2):\n","    crossover_point = np.random.randint(1, len(parent1) - 1)\n","    child1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n","    child2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n","    return child1, child2\n","\n","def mutate(individual, mutation_rate):\n","    mutation_mask = np.random.rand(len(individual)) < mutation_rate\n","    individual[mutation_mask] = 1 - individual[mutation_mask] \n","    return individual\n","\n","def genetic_algorithm(X_train, X_test, y_train, y_test, num_generations=5, population_size=5, crossover_rate=0.8, mutation_rate=0.01):\n","    num_individuals, num_features = population_size, X_train.shape[1]\n","    population = initialize_population(num_individuals, num_features)\n","    \n","    seleksi_fiturpergenerasi = []\n","    for generation in range(num_generations):\n","        \n","        #evaluasi fittest tiap gen\n","        fitness_scores = [fitness(individual, X_train, X_test, y_train, y_test) for individual in population]\n","\n","        selected_indices = np.argsort(fitness_scores)[::-1][:int(crossover_rate * population_size)]\n","        selected_population = population[selected_indices]\n","\n","        #crossover\n","        new_population = []\n","        for _ in range(num_individuals // 2):\n","            idx_parent1, idx_parent2 = np.random.choice(len(selected_population), size=2, replace=False)\n","            parent1, parent2 = selected_population[idx_parent1], selected_population[idx_parent2]\n","            child1, child2 = crossover(parent1, parent2)\n","            new_population.extend([child1, child2])\n","\n","        #mutasi gen\n","        new_population = [mutate(individual, mutation_rate) for individual in new_population]\n","\n","        #menggantikan populasi lama dgn baru\n","        population[:len(new_population)] = new_population\n","\n","        #print hasil terbaik tiap generasi\n","        best_fitness = np.max(fitness_scores)\n","        print(f\"Generation {generation + 1}, Best Fitness: {best_fitness:.4f}\")\n","        seleksi_fiturpergenerasi.append([np.where(individual == 1)[0] for individual in population])\n","\n","    best_individual = population[np.argmax(fitness_scores)]\n","\n","    # Cetak atau tampilkan informasi fitur yang dipilih pada setiap generasi\n","    for gen, selected_features in enumerate(seleksi_fiturpergenerasi):\n","        print(f\"Generation {gen + 1}: Selected features for each individual: {selected_features}\")\n","\n","\n","    return best_individual\n","\n"," \n","X = df.drop(columns=['judulpluskonten','preproses_text','label','vec'])\n","y = df.label\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n","\n","best_individual = genetic_algorithm(X_train, X_test, y_train, y_test,num_generations=5,population_size=10)\n","\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Classifier</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>RandomForest</td>\n","      <td>0.87075</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GradientBoosting</td>\n","      <td>0.84550</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>LinearSVM</td>\n","      <td>0.82575</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Logistic</td>\n","      <td>0.81775</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AdaBoost</td>\n","      <td>0.81725</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>KNeighbors</td>\n","      <td>0.81175</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>DecisionTree</td>\n","      <td>0.79150</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>RadialSVM</td>\n","      <td>0.78525</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Classifier  Accuracy\n","0      RandomForest   0.87075\n","1  GradientBoosting   0.84550\n","2         LinearSVM   0.82575\n","3          Logistic   0.81775\n","4          AdaBoost   0.81725\n","5        KNeighbors   0.81175\n","6      DecisionTree   0.79150\n","7         RadialSVM   0.78525"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["X = df.drop(columns=['judulpluskonten','preproses_text','label','vec'])\n","y = df.label\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n","\n","score1 = acc_score(X_train, X_test, y_train, y_test)\n","score1"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1]\n"]}],"source":["print(best_individual)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1]\n"]}],"source":["print(best_individual)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"Lm5mxkOMnsj5"},"outputs":[{"data":{"text/plain":["(20000, 14)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["df_seleksi = df[['Number of Determinants',\n","       'Number of Short Sentence', 'Number of Long Sentence', 'smog_index',\n","       'Subjectivity','Rate Adjective and Adverb','number of special karakter',\n","       'number of capital letter', 'gunning_fog_index', 'ari',\n","       'number of word','number of verb',\n","       'number of adjective','label']]\n","df_seleksi.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_seleksi.to_csv('G:\\My Drive\\Tugas SEM3\\Kecerdasan Artifisial\\Project AI\\df_seleksi.csv',index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMy4IWiR2l9JbodykByNKK+","gpuType":"T4","mount_file_id":"14lmlakaqnXwgeGIEavhhBfut22dmoHb0","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
